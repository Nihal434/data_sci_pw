{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q1. You are working on a machine learning project where you have a dataset containing numerical and\n",
    "categorical features. You have identified that some of the features are highly correlated and there are\n",
    "missing values in some of the columns. You want to build a pipeline that automates the feature\n",
    "engineering process and handles the missing values.`\n",
    "\n",
    "`Design a pipeline that includes the following steps:`\n",
    "\n",
    "1. Use an automated feature selection method to identify the important features in the dataset.\n",
    "\n",
    "`Create a numerical pipeline that includes the following steps:`\n",
    "1. Impute the missing values in the numerical columns using the mean of the column values.\n",
    "2. Scale the numerical columns using standardisation\n",
    "\n",
    "`Create a categorical pipeline that includes the following steps:`\n",
    "1. Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "2. One-hot encode the categorical columns.\n",
    "\n",
    "- Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "- Use a Random Forest Classifier to build the final model\n",
    "- Evaluate the accuracy of the model on the test dataset.\n",
    "\n",
    "Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define the categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combine the numerical and categorical pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, ['numerical_feature_1', 'numerical_feature_2']),\n",
    "    ('cat', cat_pipeline, ['categorical_feature_1', 'categorical_feature_2'])\n",
    "])\n",
    "\n",
    "# Use SelectFromModel to perform automated feature selection\n",
    "selector = SelectFromModel(RandomForestClassifier(random_state=42))\n",
    "selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Define the final pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', selector),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the final pipeline on the training data\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test dataset\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this pipeline, we first load the dataset and split it into train and test sets. Then we define two pipelines, one for the numerical features and one for the categorical features. The numerical pipeline first imputes the missing values in the numerical columns using the mean of the column values and then scales the columns using standardization. The categorical pipeline first imputes the missing values in the categorical columns using the most frequent value of the column and then one-hot encodes the columns.\n",
    "\n",
    "We then use ColumnTransformer to combine the numerical and categorical pipelines. This allows us to apply different preprocessing steps to different types of features in the dataset. We also use SelectFromModel to perform automated feature selection, which identifies the important features in the dataset.\n",
    "\n",
    "Finally, we define the final pipeline that includes the preprocessor, feature selection, and a Random Forest Classifier. We fit this pipeline on the training data and evaluate its accuracy on the test dataset.\n",
    "\n",
    "Possible improvements for this pipeline include trying different imputation strategies, feature selection methods, and models to find the best combination for the dataset. Additionally, it may be useful to perform further exploratory data analysis to identify any other issues with the dataset that may affect model performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
    "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its\n",
    "accuracy.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "\n",
    "#loading Iris dataset\n",
    "df = sns.load_dataset(\"iris\")\n",
    "X = df.drop('species',axis =1)\n",
    "y = df.species\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "numerical_features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "categorical_features = []\n",
    "\n",
    "# Define the numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define the categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combine the numerical and categorical pipelines using a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Define the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define the Logistic Regression Classifier\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('lr', lr)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Define the final pipeline that includes the preprocessor and the Voting Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', voting_clf)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the pipeline on the test data\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this pipeline, we first define a numerical pipeline and a categorical pipeline that handle the missing values and apply scaling and one-hot encoding respectively. Then we combine these pipelines using a ColumnTransformer.\n",
    "\n",
    "Next, we define the Random Forest Classifier and the Logistic Regression Classifier. We then define the Voting Classifier that combines the predictions of these classifiers.\n",
    "\n",
    "Finally, we define the complete pipeline that includes the preprocessor and the Voting Classifier, and fit it on the training data. We evaluate the accuracy of the pipeline on the test data using the `score` method.\n",
    "\n",
    "Note that we set the voting parameter of the `Voting` Classifier to `soft`, which means that the predicted probabilities of the classifiers are averaged to compute the final prediction. If we set it to `hard`, the class with the highest number of votes is selected as the final prediction.\n",
    "\n",
    "The advantage of using a Voting Classifier is that it can improve the accuracy and robustness of the predictions by combining the strengths of multiple classifiers. The main limitation is that it may not work well if the individual classifiers have high correlation in their errors or predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
