{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Naïve bayes-2`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Bayes' theorem to calculate the probability that an employee is a smoker given that he/she uses the health insurance plan:\n",
    "\n",
    "Let S be the event that an employee is a smoker, and H be the event that an employee uses the health insurance plan.\n",
    "\n",
    "We want to calculate P(S|H), the probability that an employee is a smoker given that he/she uses the health insurance plan.\n",
    "\n",
    "Conditional probability is defined as:\n",
    "\n",
    "If P(H) > 0, we define the probability of E given F as\n",
    "P(S | H)  = P(S ∩ H)/ P(H)\n",
    "\n",
    "where \n",
    "* P(S ∩ H) = probability of employees who are smokers and use health insurance plan\n",
    "* P(H) = probablity of employees who use the health insurance plan\n",
    "\n",
    "data give:\n",
    "- P(S ∩ H) = 0.4\n",
    "- P(H) = 0.7\n",
    "\n",
    "P(S | H) = 0.4/0.7 = 0.571\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes algorithm, which are used for text classification and other applications.\n",
    "\n",
    "The main difference between these two algorithms lies in the way they model the data.\n",
    "\n",
    "In Bernoulli Naive Bayes, the data is binary, i.e., it takes on values of 0 or 1. For example, in text classification, a document can be represented as a binary vector where each element represents the presence or absence of a word in the document. Bernoulli Naive Bayes assumes that each feature (i.e., word) is conditionally independent given the class label, and models the data as a set of binary variables.\n",
    "\n",
    "In Multinomial Naive Bayes, the data is represented as a count of occurrences of each feature. For example, in text classification, a document can be represented as a vector of word counts. Multinomial Naive Bayes assumes that the data follows a multinomial distribution, and models the data as a set of count variables.\n",
    "\n",
    "To summarize:\n",
    "\n",
    "1. Bernoulli Naive Bayes is used when the data is binary (0/1).\n",
    "2. Multinomial Naive Bayes is used when the data is a count of occurrences.\n",
    "3. Bernoulli Naive Bayes models the data as a set of binary variables.\n",
    "4. Multinomial Naive Bayes models the data as a set of count variables.\n",
    "5. Both algorithms assume that the features are conditionally independent given the class label."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q3. How does Bernoulli Naive Bayes handle missing values?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes assumes that the input data is a binary feature vector, where each feature is either present (1) or absent (0). Bernoulli Naive Bayes algorithm can handle missing data. Attributes are handled separately by the algorithm, at both model construction time and prediction time. As such, if a data instance has a missing value for an attribute, it can be ignored while preparing the model, and ignored when a probability is calculated for a class value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q4. Can Gaussian Naive Bayes be used for multi-class classification?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. In Gaussian Naive Bayes, each feature is assumed to follow a Gaussian (normal) distribution, and the class-conditional probability density function is estimated for each class. Given a new input, the model calculates the probability of the input belonging to each class, and assigns the input to the class with the highest probability.\n",
    "\n",
    "For multi-class classification, the same approach is used, but with more than two classes. Specifically, for a dataset with K classes, the model estimates K class-conditional Gaussian distributions for each feature, and uses Bayes' theorem to calculate the probability of each class given the input. The class with the highest probability is then assigned as the predicted class label.\n",
    "\n",
    "Note that while Gaussian Naive Bayes can be used for multi-class classification, it may not always be the best choice, especially if the classes are not well-separated or if there are complex dependencies between the features. In such cases, other algorithms such as decision trees or neural networks may be more effective."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q5. Assignment:`\n",
    "\n",
    "`Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.`\n",
    "\n",
    "`Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.`\n",
    "\n",
    "`Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score`\n",
    "\n",
    "`Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?`\n",
    "\n",
    "`Conclusion:`\n",
    "`Summarise your findings and provide some suggestions for future work.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4600 non-null   float64\n",
      " 1   0.64    4600 non-null   float64\n",
      " 2   0.64.1  4600 non-null   float64\n",
      " 3   0.1     4600 non-null   float64\n",
      " 4   0.32    4600 non-null   float64\n",
      " 5   0.2     4600 non-null   float64\n",
      " 6   0.3     4600 non-null   float64\n",
      " 7   0.4     4600 non-null   float64\n",
      " 8   0.5     4600 non-null   float64\n",
      " 9   0.6     4600 non-null   float64\n",
      " 10  0.7     4600 non-null   float64\n",
      " 11  0.64.2  4600 non-null   float64\n",
      " 12  0.8     4600 non-null   float64\n",
      " 13  0.9     4600 non-null   float64\n",
      " 14  0.10    4600 non-null   float64\n",
      " 15  0.32.1  4600 non-null   float64\n",
      " 16  0.11    4600 non-null   float64\n",
      " 17  1.29    4600 non-null   float64\n",
      " 18  1.93    4600 non-null   float64\n",
      " 19  0.12    4600 non-null   float64\n",
      " 20  0.96    4600 non-null   float64\n",
      " 21  0.13    4600 non-null   float64\n",
      " 22  0.14    4600 non-null   float64\n",
      " 23  0.15    4600 non-null   float64\n",
      " 24  0.16    4600 non-null   float64\n",
      " 25  0.17    4600 non-null   float64\n",
      " 26  0.18    4600 non-null   float64\n",
      " 27  0.19    4600 non-null   float64\n",
      " 28  0.20    4600 non-null   float64\n",
      " 29  0.21    4600 non-null   float64\n",
      " 30  0.22    4600 non-null   float64\n",
      " 31  0.23    4600 non-null   float64\n",
      " 32  0.24    4600 non-null   float64\n",
      " 33  0.25    4600 non-null   float64\n",
      " 34  0.26    4600 non-null   float64\n",
      " 35  0.27    4600 non-null   float64\n",
      " 36  0.28    4600 non-null   float64\n",
      " 37  0.29    4600 non-null   float64\n",
      " 38  0.30    4600 non-null   float64\n",
      " 39  0.31    4600 non-null   float64\n",
      " 40  0.33    4600 non-null   float64\n",
      " 41  0.34    4600 non-null   float64\n",
      " 42  0.35    4600 non-null   float64\n",
      " 43  0.36    4600 non-null   float64\n",
      " 44  0.37    4600 non-null   float64\n",
      " 45  0.38    4600 non-null   float64\n",
      " 46  0.39    4600 non-null   float64\n",
      " 47  0.40    4600 non-null   float64\n",
      " 48  0.41    4600 non-null   float64\n",
      " 49  0.42    4600 non-null   float64\n",
      " 50  0.43    4600 non-null   float64\n",
      " 51  0.778   4600 non-null   float64\n",
      " 52  0.44    4600 non-null   float64\n",
      " 53  0.45    4600 non-null   float64\n",
      " 54  3.756   4600 non-null   float64\n",
      " 55  61      4600 non-null   int64  \n",
      " 56  278     4600 non-null   int64  \n",
      " 57  1       4600 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into independent and dependent features\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4600, 57), (4600,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirming the split\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3680, 57), (920, 57))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cross validation\n",
    "parameters = {\n",
    "    \"alpha\" : [1.0],\n",
    "    \"force_alpha\" : [False] ,\n",
    "    \"binarize\" : [0],\n",
    "    \"fit_prior\" : [True ],\n",
    "    \"class_prior\" : [None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(classifier ,param_grid=parameters,scoring=\"accuracy\" , cv = 10 , verbose= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV 1/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.883 total time=   0.0s\n",
      "[CV 2/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.856 total time=   0.0s\n",
      "[CV 3/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.913 total time=   0.0s\n",
      "[CV 4/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.870 total time=   0.0s\n",
      "[CV 5/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.902 total time=   0.0s\n",
      "[CV 6/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.880 total time=   0.0s\n",
      "[CV 7/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.897 total time=   0.0s\n",
      "[CV 8/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.889 total time=   0.0s\n",
      "[CV 9/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.889 total time=   0.0s\n",
      "[CV 10/10] END alpha=1.0, binarize=0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.913 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=BernoulliNB(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1.0], &#x27;binarize&#x27;: [0], &#x27;class_prior&#x27;: [None],\n",
       "                         &#x27;fit_prior&#x27;: [True], &#x27;force_alpha&#x27;: [False]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=BernoulliNB(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1.0], &#x27;binarize&#x27;: [0], &#x27;class_prior&#x27;: [None],\n",
       "                         &#x27;fit_prior&#x27;: [True], &#x27;force_alpha&#x27;: [False]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=BernoulliNB(),\n",
       "             param_grid={'alpha': [1.0], 'binarize': [0], 'class_prior': [None],\n",
       "                         'fit_prior': [True], 'force_alpha': [False]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_BNB = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB classification reprot\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       530\n",
      "           1       0.89      0.79      0.84       390\n",
      "\n",
      "    accuracy                           0.87       920\n",
      "   macro avg       0.88      0.86      0.87       920\n",
      "weighted avg       0.87      0.87      0.87       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"BernoulliNB classification reprot\")\n",
    "print(classification_report(y_test , y_pred_BNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cross validation\n",
    "parameters = {\n",
    "    \"alpha\" : [1.0],\n",
    "    \"force_alpha\" : [False],\n",
    "    \"fit_prior\" : [True ],\n",
    "    \"class_prior\" : [None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(classifier ,param_grid=parameters,scoring=\"accuracy\" , cv = 10 , verbose= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV 1/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.777 total time=   0.0s\n",
      "[CV 2/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.818 total time=   0.0s\n",
      "[CV 3/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.818 total time=   0.0s\n",
      "[CV 4/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.802 total time=   0.0s\n",
      "[CV 5/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.818 total time=   0.0s\n",
      "[CV 6/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.799 total time=   0.0s\n",
      "[CV 7/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.818 total time=   0.0s\n",
      "[CV 8/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.739 total time=   0.0s\n",
      "[CV 9/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.791 total time=   0.0s\n",
      "[CV 10/10] END alpha=1.0, class_prior=None, fit_prior=True, force_alpha=False;, score=0.774 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=MultinomialNB(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1.0], &#x27;class_prior&#x27;: [None],\n",
       "                         &#x27;fit_prior&#x27;: [True], &#x27;force_alpha&#x27;: [False]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=MultinomialNB(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1.0], &#x27;class_prior&#x27;: [None],\n",
       "                         &#x27;fit_prior&#x27;: [True], &#x27;force_alpha&#x27;: [False]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [1.0], 'class_prior': [None],\n",
       "                         'fit_prior': [True], 'force_alpha': [False]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MNB = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial classification reprot\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       530\n",
      "           1       0.75      0.68      0.71       390\n",
      "\n",
      "    accuracy                           0.77       920\n",
      "   macro avg       0.76      0.76      0.76       920\n",
      "weighted avg       0.77      0.77      0.76       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Multinomial classification reprot\")\n",
    "print(classification_report(y_test , y_pred_MNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cross validation\n",
    "parameters = {\n",
    "    \"priors\" : [None],\n",
    "    \"var_smoothing\" :[np.e**(-9)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(classifier ,param_grid=parameters,scoring=\"accuracy\" , cv = 10 , verbose= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV 1/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.658 total time=   0.0s\n",
      "[CV 2/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.666 total time=   0.0s\n",
      "[CV 3/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.688 total time=   0.0s\n",
      "[CV 4/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.688 total time=   0.0s\n",
      "[CV 5/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.668 total time=   0.0s\n",
      "[CV 6/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.707 total time=   0.0s\n",
      "[CV 7/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.666 total time=   0.0s\n",
      "[CV 8/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.663 total time=   0.0s\n",
      "[CV 9/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.652 total time=   0.0s\n",
      "[CV 10/10] END priors=None, var_smoothing=0.00012340980408667962;, score=0.658 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;priors&#x27;: [None],\n",
       "                         &#x27;var_smoothing&#x27;: [0.00012340980408667962]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;priors&#x27;: [None],\n",
       "                         &#x27;var_smoothing&#x27;: [0.00012340980408667962]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'priors': [None],\n",
       "                         'var_smoothing': [0.00012340980408667962]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GNB = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB classification reprot\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       530\n",
      "           1       0.75      0.68      0.71       390\n",
      "\n",
      "    accuracy                           0.77       920\n",
      "   macro avg       0.76      0.76      0.76       920\n",
      "weighted avg       0.77      0.77      0.76       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GaussianNB classification reprot\")\n",
    "print(classification_report(y_test , y_pred_MNB))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final scores:\n",
    "|model|accuracy|precision|recall|f1 score|\n",
    "|-----|--------|---------|------|--------|\n",
    "|BernoulliNB|87%|89%|79%|84%|\n",
    "|Multinomial|77%|75%|68%|71%|\n",
    "|Gaussian|77%|75%|68%|71%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion: \n",
    "The Bernoulli Naive Bayes model had the highest accuracy compared to all and it had the highest precision , recall and f1 scores compared to Multinomial or Gaussian NB classifier. This is because bernoulli NB classifier is good for binary classification problem statement as Bernoulli Naive Bayes is very good if the predictor variable has binary outcomes like whether the outcome is spam (1) or not spam(0). Therefore it has fared better compared to other methods. On the other hand multinomial classfication is more suitable when the predictor variable has mutiple categorical outcomes and Gaussain NB suits data which follows Guassian distribution.\n",
    "\n",
    "While Naive Bayes is a powerful and widely used classification algorithm, it also has some limitations:\n",
    "\n",
    "1. **`Strong independence assumption`**: Naive Bayes assumes that all features are independent, which is often not the case in real-world data. This can lead to suboptimal performance if there are correlations or dependencies between features.\n",
    "\n",
    "2. **`Sensitivity to irrelevant features`**: Naive Bayes can be sensitive to irrelevant features, which can have a negative impact on its performance. This is because the algorithm treats all features equally and assigns equal weight to each feature, regardless of its relevance to the classification task.\n",
    "\n",
    "3. **`Limited expressive power`**: Naive Bayes can only model linear decision boundaries, which can be a limitation when dealing with complex or nonlinear datasets.\n",
    "\n",
    "4. **`Limited data`**: Naive Bayes requires a sufficient amount of data to accurately estimate the class-conditional probabilities. If the amount of training data is limited, the algorithm may suffer from overfitting or underfitting.\n",
    "\n",
    "5. **`Handling of continuous data`**: The standard implementation of Naive Bayes assumes that the input features are categorical or binary. Handling continuous data requires discretization or modeling the features as continuous variables, which can be computationally expensive.\n",
    "\n",
    "Despite these limitations, Naive Bayes remains a popular and effective classification algorithm, particularly for high-dimensional datasets with sparse features. Its simplicity, efficiency, and ease of implementation make it a good choice for many real-world applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "\n",
    "1. Bernoulli NB had the highest scores interms of all parameters when compared to other methods like polynomial or guassian NB because the target varaible had binary outcomes. \n",
    "2. Bernoulli NB assumes that the features are categorical / binary in nature therefore applying it to continous data may not yield best results.\n",
    "3. Since the dataset has limited number of observations the bernoulli Nb does not attain very high accuracy scores and more data may be required to develop better models\n",
    "4. The model was trained with default parameters therefore to improve accuracy we can try out different parameters for our models during cross valdation\n",
    "5. Logistic regression is very good in situations where features are continous in nature and outcome is binary and this can be tested out in future\n",
    "6. Randome forest classifier may also be suitable for our problem statement and this can also be tried out in the future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
