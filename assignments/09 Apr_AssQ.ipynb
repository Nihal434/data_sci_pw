{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Naïve bayes-1`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q1. What is Bayes' theorem?`\n",
    "\n",
    "`&`\n",
    "\n",
    "`Q2. What is the formula for Bayes' theorem?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayes' theorem** is a mathematical formula used in probability theory and statistics to calculate the probability of an event based on prior knowledge or belief about the conditions that may be related to the event. The theorem is named after Reverend Thomas Bayes, an 18th-century British statistician and Presbyterian minister.\n",
    "\n",
    "In its simplest form, Bayes' theorem can be expressed as:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)<br>\n",
    "\n",
    "Where:<br>\n",
    "\n",
    "- P(A|B) is the conditional probability of A given B.\n",
    "- P(B|A) is the conditional probability of B given A.\n",
    "- P(A) is the prior probability of A (i.e., the probability of A before considering B).\n",
    "- P(B) is the prior probability of B.<br>\n",
    "\n",
    "Bayes' theorem can be used to update the probability of an event based on new evidence, making it a useful tool in fields such as medicine, engineering, finance, and artificial intelligence.\n",
    "\n",
    "To use Bayes' theorem, we start with a prior probability and then update it based on new evidence. For example, suppose we are trying to diagnose a patient who presents with certain symptoms. We might start with a prior probability of the patient having a certain disease, based on the prevalence of the disease in the population. As we gather more information, such as the results of tests, we can update our probability using Bayes' theorem.\n",
    "\n",
    "For example, let's say that we have a patient who presents with symptoms that could be caused by either Disease A or Disease B. The prior probability of the patient having Disease A is 0.2 (20%), and the prior probability of the patient having Disease B is 0.3 (30%). We perform a test that is 90% accurate for Disease A and 80% accurate for Disease B. The test comes back positive.\n",
    "\n",
    "Using Bayes' theorem, we can update our probabilities as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "P(A|B) = (0.9 * 0.2) / ((0.9 * 0.2) + (0.2 * 0.1))\n",
    "P(A|B) = 0.818\n",
    "\n",
    "P(B|A) = (P(A|B) * P(B)) / P(A)\n",
    "P(B|A) = (0.818 * 0.3) / ((0.818 * 0.3) + (0.1 * 0.8))\n",
    "P(B|A) = 0.621\n",
    "\n",
    "Therefore, the probability of the patient having Disease A given a positive test result is 81.8%, and the probability of the patient having Disease B given a positive test result is 62.1%.\n",
    "\n",
    "Bayes' theorem is a powerful tool that allows us to update our probabilities as we gather more information, making it a valuable tool in many fields."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q3. How is Bayes' theorem used in practice?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in many practical applications across various fields. Some common examples include:\n",
    "\n",
    "1. **Spam filtering**: Bayes' theorem is used to filter out spam emails from legitimate emails. In this application, the prior probability is based on the frequency of certain words in spam emails versus legitimate emails. As new emails come in, their probabilities are updated based on the words they contain, and emails with a high probability of being spam are filtered out.\n",
    "\n",
    "2. **Medical diagnosis**: Bayes' theorem is used to diagnose medical conditions by combining prior probabilities with new information such as test results and symptoms. The prior probabilities are based on the prevalence of the condition in the population, and the new information is used to update the probabilities.\n",
    "\n",
    "3. **Stock market analysis**: Bayes' theorem is used to predict stock market trends by analyzing historical data and updating probabilities based on new information such as economic indicators and news events.\n",
    "\n",
    "4. **Machine learning**: Bayes' theorem is used in machine learning algorithms such as Naive Bayes, which is a probabilistic classifier that uses Bayes' theorem to predict the probability of a certain class given a set of features.\n",
    "\n",
    "5. **Risk analysis**: Bayes' theorem is used in risk analysis to calculate the probability of a certain event occurring based on prior probabilities and new information such as weather forecasts or seismic activity.\n",
    "\n",
    "Overall, Bayes' theorem is a powerful tool that allows us to update our probabilities as we gather more information, making it a valuable tool in many practical applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q4. What is the relationship between Bayes' theorem and conditional probability?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem and conditional probability are related concepts in probability theory. In fact, Bayes' theorem is a formula that relates conditional probabilities to each other.\n",
    "\n",
    "Conditional probability is the probability of an event A given that event B has occurred, and it is denoted by P(A|B). Bayes' theorem is a way of calculating this conditional probability by reversing the order of the events. Specifically, Bayes' theorem allows us to calculate the probability of event B given that event A has occurred, which is denoted by P(B|A), using the probability of event A given that event B has occurred, which is denoted by P(A|B).\n",
    "\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(B|A) = (P(A|B) * P(B)) / P(A)<br>\n",
    "\n",
    "Where:<br>\n",
    "\n",
    "P(A|B) is the probability of event A given that event B has occurred.<br>\n",
    "P(B|A) is the probability of event B given that event A has occurred.<br>\n",
    "P(B) is the prior probability of event B.<br>\n",
    "P(A) is the prior probability of event A.<br>\n",
    "\n",
    "\n",
    "Bayes' theorem tells us that the probability of event B given that event A has occurred is proportional to the probability of event A given that event B has occurred, multiplied by the prior probability of event B, and divided by the prior probability of event A."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the right type of Naive Bayes classifier for a given problem depends on several factors, including the nature of the data, the size of the dataset, and the goal of the analysis. Here are some general guidelines for selecting the appropriate Naive Bayes classifier:\n",
    "\n",
    "1. **Gaussian Naive Bayes**: This classifier is suitable for continuous data where the features follow a normal (Gaussian) distribution. If the dataset has continuous features and the distribution of each feature is approximately normal, then Gaussian Naive Bayes may be a good choice.\n",
    "\n",
    "2. **Multinomial Naive Bayes**: This classifier is suitable for discrete data where the features are counts or frequencies, such as text data. If the dataset has discrete features and the values represent counts or frequencies, then Multinomial Naive Bayes may be a good choice.\n",
    "\n",
    "3. **Bernoulli Naive Bayes**: This classifier is also suitable for discrete data, but it assumes that the features are binary (0 or 1). If the dataset has binary features, such as presence or absence of a certain attribute, then Bernoulli Naive Bayes may be a good choice.\n",
    "\n",
    "4. **Complement Naive Bayes**: This classifier is designed to address class imbalance problems where one class is significantly larger than the others. If the dataset has a class imbalance issue, then Complement Naive Bayes may be a good choice.\n",
    "\n",
    "In addition to these guidelines, it is always a good practice to try multiple Naive Bayes classifiers and compare their performance using appropriate evaluation metrics. The choice of the classifier ultimately depends on the specific requirements of the problem and the performance of the models on the given dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the class of a new instance with features X1=3 and X2=4 using Naive Bayes, we need to calculate the posterior probability of each class given the feature values.<br>\n",
    "\n",
    "We can use the Naive Bayes formula to calculate the posterior probability for each class:<br>\n",
    "\n",
    "P(A|X1=3, X2=4) = P(X1=3|A) * P(X2=4|A) * P(A) / P(X1=3, X2=4)<br>\n",
    "\n",
    "P(B|X1=3, X2=4) = P(X1=3|B) * P(X2=4|B) * P(B) / P(X1=3, X2=4)<br>\n",
    "\n",
    "Since the prior probabilities are equal for both classes (i.e., P(A) = P(B) = 0.5), we can ignore them in the calculation and focus on the likelihoods and evidence.<br>\n",
    "\n",
    "To calculate the likelihoods, we need to find the frequency of each feature value for each class. Using the table provided, we can see that:<br>\n",
    "\n",
    "P(X1=3|A) = 4/10 = 0.4<br>\n",
    "P(X1=3|B) = 1/5 ≈ 0.2<br>\n",
    "P(X2=4|A) = 3/12 = 0.25<br>\n",
    "P(X2=4|B) = 3/9 ≈ 0.33<br>\n",
    "\n",
    "To calculate the evidence, we need to find the marginal probability of the feature values:<br>\n",
    "\n",
    "P(X1=3, X2=4) = P(X1=3) * P(X2=4)<br>\n",
    "= (4/10 + 1/4) * (3/12 + 3/9)<br>\n",
    "= 0.348<br>\n",
    "\n",
    "Now, we can plug these values into the Naive Bayes formula to calculate the posterior probabilities:<br>\n",
    "\n",
    "P(A|X1=3, X2=4) = 0.4 * 0.25 / 0.348  ≈ 0.598<br>\n",
    "P(B|X1=3, X2=4) = 0.2 * 0.33 / 0.348 ≈ 0.189<br>\n",
    "\n",
    "Therefore, Naive Bayes would predict that the new instance belongs to class A since it has a higher posterior probability than class B.<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
